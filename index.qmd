---
title: "Demo Perfil Taxonómico usando Kraken y BioBackery"
author: "OMICs analysis"
format: 
  html:
    toc: true
    toc-depth: 3
    theme: yeti
    toc-location: left-body
    smooth-scroll: true
    toc-title: "Contenido"
editor: visual
execute:
  engine: knitr
lang: es
---

![](images/logo_OAN_for_white.png){fig-align="center" width="300"}

# Instalaciones y configuraciones

### Kraken2

Se realizaron las siguientes descargas directamente desde la terminal:

```{bash, eval=FALSE}
sudo apt update
sudo apt install build-essential g++ libomp-dev wget rsync perl git
sudo apt install zlib1g-dev
```

Posteriormente se clonó el repositorio de `Kraken` para poder instalarlo:

```{bash, eval=FALSE}
cd old 
git clone https://github.com/DerrickWood/kraken2.git
cd kraken2
mkdir -p /home/ubuntu/bin/kraken2
./install_kraken2.sh /home/ubuntu/bin/kraken2
```

La base de datos que se utilizó ya venía previamente indexada, lo cual nos ahorró el paso de generarla desde cero, esta base datos es `Estándar` y contiene lo siguiente: `Refseq archaea, bacteria, viral, plasmid, human, UniVec_Core` y es de fecha 07/14/2025.

```{bash, eval=FALSE}
mkdir -p /home/ubuntu/data/db_standard
cd /home/ubuntu/data/db_standard 
wget https://genome-idx.s3.amazonaws.com/kraken/k2_standard_20250714.tar.gz
tar -xzf k2_standard_20250714.tar.gz
```

Nota: una vez que se termina de descomprimir hay que eliminar el archivo `k2_standard_20250714.tar.gz` para ahorrar espacio.

### Bracken

```{bash, eval=FALSE}
cd /home/ubuntu/bin
git clone https://github.com/jenniferlu717/Bracken.git
cd src/ && make
```

### HUMAnN y MetaPhlAn

La combinación estable y compatible es HUMAnN 3.8 con MetaPhlAn 4.1 (hay que evitar versiones más nuevas como MetaPhlAn 4.2, que rompen la integración)

```{bash, eval=FALSE}
/home/ubuntu/miniconda3/bin/conda config --add channels defaults
/home/ubuntu/miniconda3/bin/conda config --add channels bioconda
/home/ubuntu/miniconda3/bin/conda config --add channels conda-forge
/home/ubuntu/miniconda3/bin/conda config --add channels biobakery
```

```{bash, eval=FALSE}
/home/ubuntu/miniconda3/bin/conda create -n bakery_env -y
/home/ubuntu/miniconda3/bin/conda init bash
source ~/.bashrc
```

```{bash, eval=FALSE}
conda activate bakery_env
conda install humann=3.8 metaphlan=4.1 -y

```

Preparación de sus respectivas bases de datos:

```{bash, eval=FALSE}
mkdir -p /home/ubuntu/data/humann_db    
mkdir -p /home/ubuntu/data/metaphlan_db 
```

### HUMAnN data

ChocoPhlAn (completa):

```{bash, eval=FALSE}
humann_databases --download chocophlan full /home/ubuntu/data/humann_db --update-config yes 
```

Uniref90:

```{bash, eval=FALSE}
humann_databases --download uniref uniref90_diamond /home/ubuntu/data/humann_db --update-config yes
```

Utility mapping:

```{bash, eval=FALSE}
humann_databases --download utility_mapping full /home/ubuntu/data/humann_db --update-config yes
```

### MetaPhlAn data

Se usó el índice compatible mpa_vOct22_CHOCOPhlAnSGB_202403 (integración con HUMAnN 3.8):

```{bash, eval=FALSE}
metaphlan --install --bowtie2db --index mpa_vOct22_CHOCOPhlAnSGB_202403
```

## Otros softwares:

### SRATools

```{bash, eval=FALSE}
cd /home/ubuntu/bin
wget --output-document sratoolkit.tar.gz https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz
tar -vxzf sratoolkit.tar.gz
export PATH=$PWD/sratoolkit.3.2.1-ubuntu64/bin:$PATH
```

### KneadData

Se utilizó esta herramienta para hacer el proceso de `Trimmomatic` y quitar el ADN de hospedero (humano), se puede personalizar al genoma de hospedero que convenga. Es recomendable instalarla en el mismo entorno Conda (`bakery_env`) para mantener la compatibilidad y simplicidad.

```{bash, eval=FALSE}
conda install -c bioconda kneaddata -y
mkdir -p /home/ubuntu/data/kneaddata_db
kneaddata_database --download human_genome bowtie2 /home/ubuntu/data/kneaddata_db
```

### Flash

```{bash, eval=FALSE}

```

### Trimmomatic

```{bash, eval=FALSE}
cd /home/ubuntu/bin
wget http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.39.zip
unzip Trimmomatic-0.39.zip
```

### CutAdapt

```{bash, eval=FALSE}
sudo apt install cutadapt
```

# Conjunto de datos

Para este `Demo` utilizamos metagenomas de intestino de humano del estudio "[Gut microbiome composition may be an indicator of preclinical Alzheimer’s disease](https://pmc.ncbi.nlm.nih.gov/articles/PMC10680783/#S8)". Seleccionamos 3 muestras para 2 condiciones distintas, `Sintomas Pre-Clínicos de Alzheimer` vs `Pacientes Sanos`.

Aqui están los metadatos asociados a cada muestra:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
df <- readr::read_csv("tables/SraRunTable.csv")
df$`Sample Name` <- as.character(df$`Sample Name`)

meta_df <- readxl::read_xlsx("tables/NIHMS1945399-supplement-Data_file_S1_version2.xlsx", sheet = 1) 
meta_df$Participant <- as.character(meta_df$Participant)

samples <- c("24882", "62710", "63032", "62568", "63218", "63972")
sb_df <- df[df$`Sample Name` %in% samples, ]
sb_meta <- meta_df[meta_df$Participant %in% samples, ]

all <- dplyr::left_join(sb_df, sb_meta, by = c(`Sample Name` = "Participant"))
all <- all[order(all$amyloid.positive.AF),]

gt::gt(all)
```

## Descarga de los datos

```{bash, eval=FALSE}
prefetch SRR17648356
faster-dump --split-files SRR17648356/SRR17648356.sra
gzip SRR17648356_1.fastq
gzip SRR17648356_2.fastq
```

## Estructura proyecto

```{bash, eval=FALSE}
2025_Demo_Biobakery
│   ├── RUN_0_raw.sh
│   ├── RUN_1_QC.sh
│   ├── bin
│   ├── config.sh
│   ├── log
│   ├── nohup.out
│   ├── old
│   └── results
    ├── 0_raw
    │   ├── SRR17648356_1.fastq.gz
    │   ├── SRR17648356_2.fastq.gz
    │   ├── SRR17648378_1.fastq.gz
    │   ├── SRR17648378_2.fastq.gz
    │   ├── SRR17648422_1.fastq.gz
    │   ├── SRR17648422_2.fastq.gz
    │   ├── SRR17648430_1.fastq.gz
    │   ├── SRR17648430_2.fastq.gz
    │   ├── SRR17648436_1.fastq.gz
    │   ├── SRR17648436_2.fastq.gz
    │   ├── SRR17648441_1.fastq.gz
    │   └── SRR17648441_2.fastq.gz
    ├── 1_QC
    │   ├── SRR17648356_1_cutadapt.fastq.gz
    │   ├── SRR17648356_1_cutadapt.trimmed.fastq.gz
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata.log
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata.repeats.removed.1.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata.repeats.removed.2.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_hg_39_bowtie2_paired_contam_1.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_hg_39_bowtie2_paired_contam_2.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_hg_39_bowtie2_unmatched_1_contam.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_hg_39_bowtie2_unmatched_2_contam.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_paired_1.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_paired_2.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_unmatched_1.fastq
    │   ├── SRR17648356_1_cutadapt.trimmed_kneaddata_unmatched_2.fastq
    │   ├── SRR17648356_1_discard.fastq
    │   ├── SRR17648356_2_cutadapt.fastq.gz
    │   ├── SRR17648356_2_cutadapt.trimmed.fastq.gz
    │   ├── SRR17648356_2_discard.fastq
    │   ├── SRR17648356_cutadapt.log
    │   └── SRR17648356_trimmomatic.log
    ├── 2_kraken2
    ├── 3_bracken
    └── 4_humann

├── Miniconda3-latest-Linux-x86_64.sh
├── bin
│   ├── Bracken
│   ├── Trimmomatic-0.39
│   ├── automnt.sh
│   ├── aws_install.sh
│   ├── conda_install.sh
│   ├── github_keyload.sh
│   ├── github_setup.sh
│   ├── keys
│   ├── kraken2
│   ├── pull-manifest.sh
│   ├── set_repo.sh
│   └── sratoolkit.3.2.1-ubuntu64
├── data
│   ├── db_standard
│   ├── humann_db
│   ├── kneaddata_db
│   └── nohup.out
├── log
├── miniconda3
│   ├── LICENSE.txt
│   ├── _conda
│   ├── bin
│   ├── compiler_compat
│   ├── conda-meta
│   ├── condabin
│   ├── envs
│   ├── etc
│   ├── include
│   ├── lib
│   ├── libexec
│   ├── man
│   ├── pkgs
│   ├── share
│   ├── shell
│   ├── ssl
│   ├── uninstall.sh
│   └── x86_64-conda-linux-gnu
├── old
│   ├── Bracken
│   ├── kraken2
│   └── miniconda_list.html
└── snap
    └── tree
```

## Data

```{bash, eval=FALSE}
4.1G	./kneaddata_db
93G	./db_standard
16G	./humann_db/chocophlan
34G	./humann_db/uniref
2.6G	./humann_db/utility_mapping
52G	./humann_db
149G	.
```

## RUNs

-   config.sh

```{bash, eval=FALSE, echo=FALSE}
#Project environment

global_bin=/home/ubuntu/bin
projectdir=/home/ubuntu/2025_Demo_Biobakery

resultsdir=$projectdir/results
logdir=$projectdir/log

rawdir=$resultsdir/0_raw
qcdir=$resultsdir/1_QC
kraken2dir=$resultsdir/2_kraken2
brackendir=$resultsdir/3_bracken
humanndir=$resultsdir/4_humann

dbs=/home/ubuntu/data

```

-   RUN_0_raw.sh

```{bash, eval=FALSE, echo=FALSE}
source config.sh

sra_id=("SRR17648378" "SRR17648430" "SRR17648436" "SRR17648356" "SRR17648422" "SRR17648441")

export PATH=$global_bin/sratoolkit.3.2.1-ubuntu64/bin:$PATH
cd $rawdir

for id in "${sra_id[@]}"; do
	echo "SRA: $id"
	prefetch $id
	faster-dump --split-files "$rawdir/$id/$id.sra" 
	gzip "$rawdir/$id_1.fastq"
	gzip "$rawdir/$id_2.fastq"	
done
```

-   RUN_1_QC.sh

```{bash, eval=FALSE, echo=FALSE}
source config.sh

# Activar el entorno
#source /home/ubuntu/miniconda3/bin/activate bakery_env

do_cutadapt=
do_trimmomatic=
do_kneaddata=1

shutdown=
threads=8
file="SRR17648356"


if [ $do_cutadapt ]
then 

#source ~/miniconda/bin/activate cutadapt

/usr/bin/time -v\
	cutadapt -a GATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \
	--trim-n \
	--match-read-wildcards -j $threads\
	-o $qcdir/$file"_1_cutadapt.fastq.gz" -p $qcdir/$file"_2_cutadapt.fastq.gz" \
	$rawdir/$file"_1.fastq.gz" $rawdir/$file"_2.fastq.gz" > $qcdir/$file"_cutadapt.log" 2>&1

#conda deactivate

fi


if [ $do_trimmomatic ]
then
	source ~/miniconda3/bin/activate bakery_env
	echo "trimmomatic for $file"

	/usr/bin/time -v\
	java -jar /home/ubuntu/bin/Trimmomatic-0.39/trimmomatic-0.39.jar PE -threads $threads -phred33\
	$qcdir/$file"_1_cutadapt.fastq.gz" $qcdir/$file"_2_cutadapt.fastq.gz" \
	$qcdir/$file"_1_cutadapt.trimmed.fastq.gz" $qcdir/$file"_1_discard.fastq" \
	$qcdir/$file"_2_cutadapt.trimmed.fastq.gz" $qcdir/$file"_2_discard.fastq" \
	ILLUMINACLIP:/home/ubuntu/bin/Trimmomatic-0.39/adapters/NexteraPE-PE.fa:2:30:10:1:TRUE LEADING:10 TRAILING:15 SLIDINGWINDOW:4:20 AVGQUAL:25 MINLEN:60 > $qcdir/$file"_trimmomatic.log" 2>&1

	conda deactivate
fi


if [ $do_kneaddata ] 
then

	source ~/miniconda3/bin/activate bakery_env

        /usr/bin/time -v \
        kneaddata \
        -i1 $qcdir/$file"_1_cutadapt".trimmed.fastq.gz -i2 $qcdir/$file"_2_cutadapt".trimmed.fastq.gz \
        --output $qcdir \
        --reference-db $dbs/kneaddata_db \
        --threads $threads \
        --bypass-trim > $logdir/$file-$(date +%s)_kneaddata.log 2>&1
	
	conda deactivate

fi


# Autoshutdown
if [ $shutdown ]
then
	sudo shutdown now
fi
```

## Preprocemiento

Con este paso quitamos ADN contaminante del hospedero y eliminamos secuencias adaptadoras.

```{bash, eval=FALSE}
kneaddata -i1 SRR17648356_1.fastq.gz\
-i2 SRR17648356_2.fastq.gz --output out_kneaddata\
--reference-db kneaddata_db --threads 8\
--trimmomatic-options="LEADING:10"\
--trimmomatic-options="TRAILING:10"\
--trimmomatic-options="SLIDINGWINDOW:4:20"\
--trimmomatic-options="MINLEN:60" > $SRR17648356-$(date +%s)_kneaddata.log 2>&1
```

Para evitar que la memoria se llene

```{bash, eval=FALSE}
#!/bin/bash

# Source the config file
source config.sh

# Loop over each ID provided as argument
for file in "$@"; do
    # Define basename based on the input pattern
    basename="${file}_1_cutadapt.trimmed"
    
    # Define the kept files (before gzipping)
    kept1="${qcdir}/${basename}_kneaddata_paired_1.fastq"
    kept2="${qcdir}/${basename}_kneaddata_paired_2.fastq"
    
    # Run kneaddata
    kneaddata \
        -i1 "${qcdir}/${file}_1_cutadapt.trimmed.fastq.gz" \
        -i2 "${qcdir}/${file}_2_cutadapt.trimmed.fastq.gz" \
        --output "${qcdir}" \
        --reference-db "${dbs}/kneaddata_db" \
        --threads "${threads}" \
        --bypass-trim > "${logdir}/${file}-$(date +%s)_kneaddata.log" 2>&1
    
    # Compress the kept files
    gzip "${kept1}"
    gzip "${kept2}"
    
    # Define the compressed kept files
    kept1_gz="${kept1}.gz"
    kept2_gz="${kept2}.gz"
    
    # Delete all other files related to this ID
    find "${qcdir}" -name "${file}_*" ! -name "$(basename "${kept1_gz}")" ! -name "$(basename "${kept2_gz}")" -delete
done

```
